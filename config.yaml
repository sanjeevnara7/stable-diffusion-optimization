#YAML Config for benchmarking

#Run name for wandb logging
run_name: sdbenchmark_fp16_tome0.5_distilledsdTiny_tinyAE_jit-vae+unet

#Path to SD model on HuggingFace. Can be changed if using distlled stable diffusion
  #base: runwayml/stable-diffusion-v1-5
  #distilled-small: segmind/small-sd
  #distilled-tiny: segmind/tiny-sd 
model_path: segmind/tiny-sd

#Quantization
precision: half #single, half, int (int8)
autocast: false #automatic mixed precision torch.autocast

#Attention mechanism
attention: SDPA #SDPA OR xFormers OR vanilla OR sliced, SDPA is the default (also enabled by default in PyTorch 2.0+)

#Token merging
token_merging:
  use_tome: false
  ratio: 0.5 #Ratio in range [0.0, 1.0]

#Tiny Autoencoder
tiny_autoencoder: true

#JIT compilation
jit_compile:
  use_jit: true
  components: #Specify which components to compile (unet, vae, or both)
    - vae
    - unet

#Prompt config
prompts:
  - a photo of an astronaut riding a horse on mars
  - A high tech solarpunk utopia in the Amazon rainforest
  - A pikachu fine dining with a view to the Eiffel Tower
  - A mecha robot in a favela in expressionist style
  - an insect robot preparing a delicious meal
  - A small cabin on top of a snowy mountain in the style of Disney, artstation

#Inference config for image generation
inference_config:
  height: 512
  width: 512
  negative_prompt: ugly, deformed
  num_images_per_prompt: 1
  num_inference_steps: 30
  guidance_scale: 7.5


